package worker

import (
	"context"
	"fmt"
	"log"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/feature/s3/manager" // ğŸ”¥ æ–°å¢ä¾èµ–
	"github.com/aws/aws-sdk-go-v2/service/s3"
	"github.com/aws/aws-sdk-go-v2/service/s3/types"
	"go.mongodb.org/mongo-driver/bson"
	"go.mongodb.org/mongo-driver/bson/primitive"
	"go.mongodb.org/mongo-driver/mongo"
	"golang.org/x/sync/semaphore"

	"s3-sync-pro/internal/database"
	"s3-sync-pro/internal/model"
	"s3-sync-pro/internal/service"
)

type Syncer struct {
	TaskID       primitive.ObjectID
	Ctx          context.Context
	Cancel       context.CancelFunc
	task         *model.Task
	srcClient    *s3.Client
	destClient   *s3.Client
	mongoTaskCol *mongo.Collection
	mongoErrCol  *mongo.Collection
	syncedObj    int64
	failedObj    int64
	skippedObj   int64
	totalObj     int64
}

func StartSync(taskID string) {
	ctx, cancel := context.WithCancel(context.Background())
	RegisterTask(taskID, cancel)
	defer UnregisterTask(taskID)

	objID, _ := primitive.ObjectIDFromHex(taskID)
	s := &Syncer{
		TaskID:       objID,
		Ctx:          ctx,
		Cancel:       cancel,
		mongoTaskCol: database.GetCollection("tasks"),
		mongoErrCol:  database.GetCollection("task_errors"),
	}

	var task model.Task
	if err := s.mongoTaskCol.FindOne(ctx, bson.M{"_id": objID}).Decode(&task); err != nil {
		log.Printf("[Error] Task %s not found: %v", taskID, err)
		return
	}
	s.task = &task
	s.updateStatus(model.StatusRunning)

	var err error
	s.srcClient, err = service.GetS3ClientForBucket(ctx, task.SourceAccountID, task.SourceBucket)
	if err != nil {
		s.failTask(fmt.Sprintf("Init Source Client Failed: %v", err))
		return
	}
	s.destClient, err = service.GetS3ClientForBucket(ctx, task.DestAccountID, task.DestBucket)
	if err != nil {
		s.failTask(fmt.Sprintf("Init Dest Client Failed: %v", err))
		return
	}

	go s.progressReporter()

	if err = s.runLoop(); err != nil {
		if err == context.Canceled {
			s.updateStatus(model.StatusPaused)
		} else {
			s.failTask(err.Error())
		}
	} else {
		s.updateStatus(model.StatusCompleted)
	}
}

func (s *Syncer) runLoop() error {
	sem := semaphore.NewWeighted(int64(s.task.Concurrency))
	wg := sync.WaitGroup{}

	listInput := &s3.ListObjectsV2Input{
		Bucket: aws.String(s.task.SourceBucket),
		Prefix: aws.String(s.task.SourcePrefix),
	}
	if s.task.NextToken != "" {
		listInput.ContinuationToken = aws.String(s.task.NextToken)
	}

	log.Printf("Task %s started. Source: %s/%s", s.TaskID.Hex(), s.task.SourceBucket, s.task.SourcePrefix)

	for {
		select {
		case <-s.Ctx.Done():
			return s.Ctx.Err()
		default:
		}

		output, err := s.srcClient.ListObjectsV2(s.Ctx, listInput)
		if err != nil {
			return fmt.Errorf("list objects failed: %v", err)
		}

		for _, obj := range output.Contents {
			atomic.AddInt64(&s.totalObj, 1)
			if err := sem.Acquire(s.Ctx, 1); err != nil {
				return err
			}
			wg.Add(1)
			go func(o types.Object) {
				defer sem.Release(1)
				defer wg.Done()
				s.processObject(o)
			}(obj)
		}

		if output.NextContinuationToken != nil {
			s.updateToken(*output.NextContinuationToken)
			listInput.ContinuationToken = output.NextContinuationToken
		} else {
			break
		}
	}
	wg.Wait()
	return nil
}

// processObject å•ä¸ªå¯¹è±¡çš„å¤„ç†é€»è¾‘
// processObject å•ä¸ªå¯¹è±¡çš„å¤„ç†é€»è¾‘
func (s *Syncer) processObject(obj types.Object) {
	key := *obj.Key
	relativePath := strings.TrimPrefix(key, s.task.SourcePrefix)
	destKey := s.task.DestPrefix + relativePath

	// 1. å¢é‡æ£€æŸ¥ (ä¿æŒä¸å˜)
	headInput := &s3.HeadObjectInput{
		Bucket: aws.String(s.task.DestBucket),
		Key:    aws.String(destKey),
	}
	destObj, err := s.destClient.HeadObject(s.Ctx, headInput)
	shouldCopy := false
	if err != nil {
		shouldCopy = true
	} else {
		if *destObj.ContentLength != *obj.Size || *destObj.ETag != *obj.ETag {
			shouldCopy = true
		}
	}

	if !shouldCopy {
		atomic.AddInt64(&s.skippedObj, 1)
		return
	}

	// ==========================================
	// 2. è·å–å¹¶ç­›é€‰æ ‡ç­¾ (é€»è¾‘ä¿®æ”¹ç‚¹)
	// ==========================================
	var tagQuery string
	
	// æ˜¾å¼è·å–æºæ ‡ç­¾
	tagOutput, err := s.srcClient.GetObjectTagging(s.Ctx, &s3.GetObjectTaggingInput{
		Bucket: aws.String(s.task.SourceBucket),
		Key:    aws.String(key),
	})

	// ğŸ¯ æ ¸å¿ƒé€»è¾‘ï¼šåªç­›é€‰ public=yes
	hasPublicTag := false
	if err == nil {
		for _, t := range tagOutput.TagSet {
			// ä¸¥æ ¼åˆ¤æ–­ Key å’Œ Value
			if *t.Key == "public" && *t.Value == "yes" {
				hasPublicTag = true
				break // æ‰¾åˆ°å°±åœæ­¢ï¼Œä¸éœ€è¦éå†å…¶ä»–çš„
			}
		}
	}

	// å¦‚æœæºæœ‰è¿™ä¸ªæ ‡ç­¾ï¼Œæˆ‘ä»¬æ‰å‡†å¤‡å†™å…¥
	if hasPublicTag {
		// S3 API è¦æ±‚æ ¼å¼: "Key1=Value1&Key2=Value2"
		tagQuery = "public=yes"
		
		// ğŸ’¡ å¦‚æœä½ è¿˜æƒ³ä¿ç•™æºæ–‡ä»¶çš„å…¶ä»–æ ‡ç­¾ï¼ŒæŠŠä¸Šé¢çš„ break å»æ‰ï¼Œ
		// ç„¶ååœ¨è¿™é‡ŒæŠŠç­›é€‰å‡ºçš„æ ‡ç­¾æ‹¼æ¥åˆ° tagQuery é‡Œã€‚
		// ä½†æ ¹æ®ä½ çš„æè¿°ï¼Œåªéœ€åˆ¤æ–­ public=yesã€‚
	}
	// ==========================================

	// 3. å°è¯•ç›´æ¥ CopyObject
	copySource := fmt.Sprintf("%s/%s", s.task.SourceBucket, key)
	copyInput := &s3.CopyObjectInput{
		Bucket:            aws.String(s.task.DestBucket),
		Key:               aws.String(destKey),
		CopySource:        aws.String(copySource),
		MetadataDirective: types.MetadataDirectiveCopy,
		ACL:               types.ObjectCannedACLBucketOwnerFullControl,
	}

	// åº”ç”¨æ ‡ç­¾ç­–ç•¥
	if tagQuery != "" {
		// æœ‰ public=yes -> æ˜¾å¼æ›¿æ¢ä¸ºæˆ‘ä»¬æŒ‡å®šçš„æ ‡ç­¾
		copyInput.TaggingDirective = types.TaggingDirectiveReplace
		copyInput.Tagging = aws.String(tagQuery)
	} else {
		// æºæ²¡æœ‰ public=yes -> æˆ‘ä»¬ä¸è®¾ç½®ä»»ä½•æ ‡ç­¾
		// æ³¨æ„ï¼šå¦‚æœä¸è®¾ç½® Tagging ä¸”ç”¨ REPLACEï¼Œç›®æ ‡å°†æ²¡æœ‰æ ‡ç­¾
		// å¦‚æœç”¨ COPYï¼ŒS3 ä¼šå°è¯•å¤åˆ¶æºçš„æ‰€æœ‰æ ‡ç­¾(åŒ…æ‹¬æˆ‘ä»¬ä¸éœ€è¦çš„)
		// æ—¢ç„¶ä½ çš„éœ€æ±‚æ˜¯â€œæ²¡æœ‰å°±å¿½ç•¥â€ï¼Œå»ºè®®ä½¿ç”¨ REPLACE ä½†ä¸ä¼  Tagging (æ¸…ç©º)ï¼Œæˆ–è€… COPY (å¦‚æœä¸åœ¨æ„å¤šä½™æ ‡ç­¾)
		
		// ä¸¥è°¨åšæ³•ï¼šæ ¹æ®éœ€æ±‚ï¼Œå¦‚æœæºæ²¡public=yesï¼Œç›®æ ‡ä¹Ÿä¸åº”è¯¥æœ‰ã€‚
		// è¿™é‡Œçš„ COPY æ„å‘³ç€å¦‚æœæºæœ‰ä¸€äº›ä¹±ä¸ƒå…«ç³Ÿçš„æ ‡ç­¾ï¼Œä¹Ÿä¼šå¸¦è¿‡å»ã€‚
		// å¦‚æœä½ æƒ³â€œé™¤äº† public=yes å…¶ä»–éƒ½ä¸è¦â€ï¼Œè¿™é‡Œåº”è¯¥ç”¨ REPLACE ä¸”ä¸èµ‹å€¼ Taggingã€‚
		// è¿™é‡Œæš‚ä¸”ä¿æŒé»˜è®¤ COPY è¡Œä¸º (å…¼å®¹æ€§æœ€å¥½)
		copyInput.TaggingDirective = types.TaggingDirectiveCopy
	}

	_, err = s.destClient.CopyObject(s.Ctx, copyInput)

	// 4. é”™è¯¯å¤„ç†ä¸é™çº§ (ä¿æŒä¸å˜)
	if err != nil {
		errMsg := err.Error()

		// é™çº§åˆ°æµå¼
		if strings.Contains(errMsg, "AccessDenied") || strings.Contains(errMsg, "403") {
			// ä¼ å…¥ç­›é€‰åçš„ tagQuery (å³åªåŒ…å« public=yes æˆ–ç©º)
			errStream := s.streamCopy(key, destKey, obj, tagQuery)
			if errStream == nil {
				atomic.AddInt64(&s.syncedObj, 1)
				return
			}
			err = errStream
		} 
		
		// é™çº§ ACL
		if strings.Contains(errMsg, "AccessControlListNotSupported") || strings.Contains(errMsg, "InvalidRequest") {
			copyInput.ACL = "" 
			_, errRetry := s.destClient.CopyObject(s.Ctx, copyInput)
			if errRetry == nil {
				atomic.AddInt64(&s.syncedObj, 1)
				return
			}
			err = errRetry
		}

		atomic.AddInt64(&s.failedObj, 1)
		log.Printf("âŒ [Sync Error] Key: %s | Err: %v", key, err)
		s.logError(key, err.Error())
	} else {
		atomic.AddInt64(&s.syncedObj, 1)
	}
}

// streamCopy æµå¼å¤åˆ¶ï¼šä¸‹è½½æµ -> å†…å­˜ç®¡é“ -> ä¸Šä¼ æµ (ä¸è½ç›˜)
func (s *Syncer) streamCopy(key, destKey string, obj types.Object, tagQuery string) error {
	// 1. è·å–æºæ–‡ä»¶ä¸‹è½½æµ
	resp, err := s.srcClient.GetObject(s.Ctx, &s3.GetObjectInput{
		Bucket: aws.String(s.task.SourceBucket),
		Key:    aws.String(key),
	})
	if err != nil {
		return fmt.Errorf("source download failed: %w", err)
	}
	// å…³é”®ï¼šå‡½æ•°ç»“æŸæ—¶å…³é—­æµï¼Œé‡Šæ”¾è¿æ¥
	defer resp.Body.Close()

	// 2. åˆå§‹åŒ–ä¸Šä¼ ç®¡ç†å™¨
	// PartSize: 5MB (é»˜è®¤)ï¼ŒConcurrency: 5 (é»˜è®¤)
	// Manager ä¼šè‡ªåŠ¨è¯»å– resp.Bodyï¼Œå¹¶åœ¨å†…å­˜ä¸­ç¼“å­˜ä¸€å°éƒ¨åˆ†æ•°æ®è¿›è¡Œåˆ†ç‰‡ä¸Šä¼ 
	uploader := manager.NewUploader(s.destClient)

	putInput := &s3.PutObjectInput{
		Bucket:        aws.String(s.task.DestBucket),
		Key:           aws.String(destKey),
		Body:          resp.Body,       // ğŸ”¥ ç›´æ¥å¯¹æ¥ä¸‹è½½æµ
		ContentLength: obj.Size,        // æ˜¾å¼å‘ŠçŸ¥å¤§å°ï¼Œé¿å… SDK ç¼“å†²æ•´ä¸ªæ–‡ä»¶
		ContentType:   resp.ContentType,
		Metadata:      resp.Metadata,
		Tagging:       aws.String(tagQuery), // ä¸Šä¼ æ—¶ç›´æ¥æ‰“æ ‡ç­¾
		ACL:           types.ObjectCannedACLBucketOwnerFullControl,
	}
	
	// å¦‚æœ tag ä¸ºç©ºï¼ŒAWS SDK ä¼šå¿½ç•¥ Tagging å­—æ®µ
	if tagQuery == "" {
		putInput.Tagging = nil
	}

	_, err = uploader.Upload(s.Ctx, putInput)
	if err != nil {
		// å†æ¬¡é™çº§ï¼šå¦‚æœæµå¼ä¸Šä¼ ä¹Ÿå› ä¸º ACL æŠ¥é”™ï¼Œå°è¯•å»æ‰ ACL
		if strings.Contains(err.Error(), "AccessControlListNotSupported") {
			putInput.ACL = ""
			_, err = uploader.Upload(s.Ctx, putInput)
		}
	}

	return err
}

// --- è¾…åŠ©å‡½æ•° ---

func (s *Syncer) progressReporter() {
	ticker := time.NewTicker(3 * time.Second)
	defer ticker.Stop()
	for {
		select {
		case <-s.Ctx.Done():
			s.flushStats()
			return
		case <-ticker.C:
			s.flushStats()
		}
	}
}

func (s *Syncer) flushStats() {
	update := bson.M{
		"$set": bson.M{
			"synced_objects":  atomic.LoadInt64(&s.syncedObj),
			"failed_objects":  atomic.LoadInt64(&s.failedObj),
			"skipped_objects": atomic.LoadInt64(&s.skippedObj),
			"total_objects":   atomic.LoadInt64(&s.totalObj),
			"updated_at":      time.Now(),
		},
	}
	s.mongoTaskCol.UpdateOne(context.Background(), bson.M{"_id": s.TaskID}, update)
}

func (s *Syncer) updateStatus(status string) {
	update := bson.M{"$set": bson.M{"status": status, "updated_at": time.Now()}}
	if status == model.StatusCompleted || status == model.StatusFailed {
		update["$set"].(bson.M)["ended_at"] = time.Now()
	}
	s.mongoTaskCol.UpdateOne(context.Background(), bson.M{"_id": s.TaskID}, update)
}

func (s *Syncer) updateToken(token string) {
	s.mongoTaskCol.UpdateOne(context.Background(), bson.M{"_id": s.TaskID}, bson.M{
		"$set": bson.M{"next_token": token},
	})
}

func (s *Syncer) failTask(reason string) {
	log.Printf("Task %s FAILED: %s", s.TaskID.Hex(), reason)
	s.mongoTaskCol.UpdateOne(context.Background(), bson.M{"_id": s.TaskID}, bson.M{
		"$set": bson.M{
			"status":     model.StatusFailed,
			"last_error": reason,
			"ended_at":   time.Now(),
		},
	})
}

func (s *Syncer) logError(key, msg string) {
	errDoc := model.TaskError{
		TaskID:    s.TaskID,
		Key:       key,
		ErrorMsg:  msg,
		Timestamp: time.Now(),
	}
	s.mongoErrCol.InsertOne(context.Background(), errDoc)
}
